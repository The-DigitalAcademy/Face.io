{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, Column, Integer, String, LargeBinary, Float\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "from deepface import DeepFace\n",
    "from deepface.commons import functions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "# create an engine to connect to the PostgreSQL database\n",
    "engine = create_engine('postgresql://postgres:@localhost:5430/faceio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceMeta(Base):\n",
    "    __tablename__ = 'face_metas'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    empl_no = Column(Integer, nullable=False)\n",
    "    img_name = Column(String, nullable=False)\n",
    "    embedding = Column(LargeBinary, nullable=False)\n",
    "\n",
    "class FaceEmbedding(Base):\n",
    "    __tablename__ = 'face_embedding'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    face_id = Column(Integer, nullable=False)\n",
    "    dimension = Column(Integer, nullable=False)\n",
    "    value = Column(Float, nullable=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing employee 0758:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 185ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing employee 0758: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s]\n",
      "Processing employee 0767:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing employee 0767: 100%|██████████| 1/1 [00:00<00:00, 15.91it/s]\n",
      "Processing employee 0760:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 97ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing employee 0760: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s]\n",
      "Processing employee 0769:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing employee 0769: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Processing employee 0756:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing employee 0756: 100%|██████████| 1/1 [00:00<00:00, 14.12it/s]\n",
      "Processing employee 0757:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing employee 0757: 100%|██████████| 1/1 [00:00<00:00, 13.13it/s]\n",
      "Processing employee 0761:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing employee 0761: 100%|██████████| 1/1 [00:00<00:00, 13.08it/s]\n",
      "Processing employee 0759:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing employee 0759: 100%|██████████| 1/1 [00:00<00:00, 13.85it/s]\n",
      "Processing employee 0763:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing employee 0763: 100%|██████████| 1/1 [00:00<00:00, 13.69it/s]\n",
      "Processing employee 0764:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing employee 0764: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s]\n",
      "Processing employee 0755:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing employee 0755: 100%|██████████| 1/1 [00:00<00:00, 12.16it/s]\n",
      "Processing employee 0765:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing employee 0765: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s]\n",
      "Processing employee 0762:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing employee 0762: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 607.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "\n",
    "Base.metadata.create_all(engine)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "model = DeepFace.build_model(\"Facenet\")\n",
    "\n",
    "facial_img_paths = []\n",
    "\n",
    "for root, directory, files in os.walk(\"/Users/ds_learner16/Documents/Face.io/deepface\"):\n",
    "    for file in files:\n",
    "        if '.jpg' in file:\n",
    "            facial_img_paths.append(root+\"/\"+file)\n",
    "\n",
    "# create dictionary to group images by employee\n",
    "employee_images = defaultdict(list)\n",
    "for facial_img_path in facial_img_paths:\n",
    "    employee_no = facial_img_path.split(\"/\")[-2] # assuming employee number is in the second-to-last directory name\n",
    "    employee_images[employee_no].append(facial_img_path)\n",
    "\n",
    "instances = []\n",
    "for employee_no, facial_img_paths in employee_images.items():\n",
    "    employee_embeddings = []\n",
    "\n",
    "    for facial_img_path in tqdm(facial_img_paths, desc=f\"Processing employee {employee_no}\"):\n",
    "        # load image and preprocess\n",
    "        img = tf.keras.preprocessing.image.load_img(facial_img_path, target_size=(160, 160))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        # represent\n",
    "        embedding = model.predict(x)[0]\n",
    "        employee_embeddings.append(embedding)\n",
    "\n",
    "        # store face embedding\n",
    "        instance = []\n",
    "        instance.append(facial_img_path)\n",
    "        instance.append(embedding)\n",
    "        instances.append(instance)\n",
    "\n",
    "    # store employee embeddings\n",
    "    employee_embeddings = np.array(employee_embeddings)\n",
    "    face_meta = FaceMeta(empl_no=employee_no, img_name=\"\", embedding=employee_embeddings.tobytes())\n",
    "    session.add(face_meta)\n",
    "\n",
    "session.commit()\n",
    "\n",
    "# store individual face embeddings\n",
    "for index, instance in tqdm(enumerate(instances), total=len(instances)):\n",
    "    img_name = instance[0]\n",
    "    embeddings = instance[1]\n",
    "\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        face_embedding = FaceEmbedding(face_id=index, dimension=i, value=float(embedding))\n",
    "        session.add(face_embedding)\n",
    "\n",
    "session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 141ms/step\n",
      "Closest match found for employee 757 with image \n"
     ]
    }
   ],
   "source": [
    "# Load target image and preprocess\n",
    "target_img = tf.keras.preprocessing.image.load_img(\"/Users/ds_learner16/Documents/Face.io/photos/val/0757/0757_test_19.jpg\", target_size=(160, 160))\n",
    "target_x = image.img_to_array(target_img)\n",
    "target_x = np.expand_dims(target_x, axis=0)\n",
    "target_x = preprocess_input(target_x)\n",
    "\n",
    "# Get embedding for target image\n",
    "target_embedding = model.predict(target_x)[0]\n",
    "\n",
    "# Query the database for face embeddings\n",
    "face_meta = session.query(FaceMeta).all()\n",
    "\n",
    "# Find closest match in database\n",
    "min_distance = float('inf')\n",
    "match_employee_no = None\n",
    "match_img_name = None\n",
    "\n",
    "for face in face_meta:\n",
    "    employee_embeddings = np.frombuffer(face.embedding, dtype=np.float32).reshape((-1, 128))\n",
    "\n",
    "    # Calculate distances between target embedding and employee embeddings\n",
    "    distances = np.linalg.norm(employee_embeddings - target_embedding, axis=1)\n",
    "\n",
    "    # Find closest match\n",
    "    closest_distance = np.min(distances)\n",
    "    if closest_distance < min_distance:\n",
    "        min_distance = closest_distance\n",
    "        match_employee_no = face.empl_no\n",
    "        match_img_name = face.img_name\n",
    "\n",
    "# Print closest match\n",
    "if match_employee_no is not None:\n",
    "    print(\"Closest match found for employee\", match_employee_no, \"with image\", match_img_name)\n",
    "else:\n",
    "    print(\"No match found in the database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load face detection model\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "# Define function to preprocess image\n",
    "def preprocess_image(img):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    # Crop face and resize to (160, 160)\n",
    "    if len(faces) > 0:\n",
    "        (x, y, w, h) = faces[0]\n",
    "        face = img[y:y+h, x:x+w]\n",
    "        face = cv2.resize(face, (160, 160))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        face = np.expand_dims(face, axis=0)\n",
    "        face = preprocess_input(face)\n",
    "        return face\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Open camera and start capturing frames\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame from camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Preprocess image\n",
    "    face = preprocess_image(frame)\n",
    "\n",
    "    # Make prediction if face is detected\n",
    "    if face is not None:\n",
    "        # Get embedding for face\n",
    "        embedding = model.predict(face)[0]\n",
    "\n",
    "        # Query the database for face embeddings\n",
    "        face_meta = session.query(FaceMeta).all()\n",
    "\n",
    "        # Find closest match in database\n",
    "        min_distance = float('inf')\n",
    "        match_employee_no = None\n",
    "        match_img_name = None\n",
    "\n",
    "        for face in face_meta:\n",
    "            employee_embeddings = np.frombuffer(face.embedding, dtype=np.float32).reshape((-1, 128))\n",
    "\n",
    "            # Calculate distances between target embedding and employee embeddings\n",
    "            distances = np.linalg.norm(employee_embeddings - embedding, axis=1)\n",
    "\n",
    "            # Find closest match\n",
    "            closest_distance = np.min(distances)\n",
    "            if closest_distance < min_distance:\n",
    "                min_distance = closest_distance\n",
    "                match_employee_no = face.empl_no\n",
    "                match_img_name = face.img_name\n",
    "\n",
    "        # Print closest match\n",
    "        if match_employee_no is not None:\n",
    "            cv2.putText(frame, \"Match found for employee {}\".format(match_employee_no), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(frame, \"No match found in database\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display frame\n",
    "    cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release camera and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepface\n",
      "  Using cached deepface-0.0.79-py3-none-any.whl (49 kB)\n",
      "Installing collected packages: deepface\n",
      "Successfully installed deepface-0.0.79\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-deps deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cosine_similarity in /Users/ds_learner16/anaconda3/lib/python3.10/site-packages (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Using cached gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/ds_learner16/anaconda3/lib/python3.10/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: six in /Users/ds_learner16/anaconda3/lib/python3.10/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/ds_learner16/anaconda3/lib/python3.10/site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: filelock in /Users/ds_learner16/anaconda3/lib/python3.10/site-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: requests[socks] in /Users/ds_learner16/anaconda3/lib/python3.10/site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/ds_learner16/anaconda3/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ds_learner16/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ds_learner16/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/ds_learner16/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ds_learner16/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/ds_learner16/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Installing collected packages: gdown\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "deepface 0.0.79 requires fire>=0.4.0, which is not installed.\n",
      "deepface 0.0.79 requires gunicorn>=20.1.0, which is not installed.\n",
      "deepface 0.0.79 requires mtcnn>=0.1.0, which is not installed.\n",
      "deepface 0.0.79 requires retina-face>=0.0.1, which is not installed.\n",
      "deepface 0.0.79 requires tensorflow>=1.9.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed gdown-4.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
